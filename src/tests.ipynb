{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_encuesta = [\n",
    "    \"name\", \"essround\", \"edition\", \"proddate\", \"idno\", \"cntry\", \"dweight\", \"pspwght\", \"pweight\", \"anweight\",\n",
    "    \"prob\", \"stratum\", \"psu\", \"netusoft\", \"nwsptot\", \"ppltrst\", \"rdtot\", \"tvtot\", \"actrolga\", \"bctprd\",\n",
    "    \"dclagr\", \"dclaid\", \"dclcrm\", \"dclenv\", \"dclmig\", \"dclwlfr\", \"dmcntov\", \"euftf\", \"gincdif\", \"ginveco\",\n",
    "    \"lawobey\", \"lrscale\", \"polintr\", \"stfeco\", \"stfedu\", \"stfgov\", \"stfhlth\", \"stflife\", \"trstplc\", \"trstplt\",\n",
    "    \"trstun\", \"trstsci\", \"imbgeco\", \"aesfdrk\", \"atchctr\", \"atcherp\", \"blgetmg\", \"brghmef\", \"brncntr\", \"dscrgnd\",\n",
    "    \"dscrrlg\", \"facntr\", \"happy\", \"health\", \"inprdsc\", \"mocntr\", \"rlgdgr\", \"sclmeet\", \"ccnthum\", \"vteumbgb\",\n",
    "    \"impenva\", \"impfreea\", \"impfuna\", \"impricha\", \"impsafea\", \"imptrada\", \"ipadvnta\", \"ipcrtiva\", \"ipeqopta\",\n",
    "    \"iplylfra\", \"ipmodsta\", \"ipudrsta\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=0.5, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.15, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=150,\n",
      "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "\n",
      "Parámetros del modelo:\n",
      "{'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.7, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'mlogloss', 'feature_types': None, 'gamma': 0.5, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.15, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 4, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 150, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "\n",
      "Importancia de las características:\n",
      "[0.06400599 0.06588753 0.06514164 0.06874122 0.07205069 0.07136354\n",
      " 0.06811275 0.06400554 0.06627379 0.08511587 0.06618456 0.07003769\n",
      " 0.06290427 0.06073134 0.0494436 ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['ppltrst', 'tvtot', 'actrolga', 'euftf', 'gincdif', 'imbgeco', 'stfgov', 'aesfdrk', 'atchctr', 'dscrgnd', 'happy', 'rlgdgr', 'ppltrst.1', 'sclmeet', 'iplylfra'] ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\nexpected actrolga, dscrgnd, atchctr, stfgov, ppltrst.1, euftf, tvtot, iplylfra, rlgdgr, ppltrst, happy, imbgeco, sclmeet, aesfdrk, gincdif in input data\ntraining data did not have the following fields: 2, 12, 7, 6, 18, 19, 16, 11, 14, 8, 3, 1, 10, 13, 0, 5, 15, 9, 17, 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m num_caracteristicas \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m# Obtener el número de características, o usar un valor por defecto si X_train no está definido.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m nuevos_datos \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(num_filas, num_caracteristicas))\n\u001b[1;32m---> 34\u001b[0m predicciones \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnuevos_datos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicciones:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicciones)\n",
      "File \u001b[1;32mc:\\GitHubRepos\\ProyectoFinal\\.FPJBGPCSobremesa-env\\Lib\\site-packages\\xgboost\\sklearn.py:1565\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1562\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1563\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1565\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1573\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\GitHubRepos\\ProyectoFinal\\.FPJBGPCSobremesa-env\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\GitHubRepos\\ProyectoFinal\\.FPJBGPCSobremesa-env\\Lib\\site-packages\\xgboost\\core.py:2514\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2512\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2514\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2516\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\GitHubRepos\\ProyectoFinal\\.FPJBGPCSobremesa-env\\Lib\\site-packages\\xgboost\\core.py:3079\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3074\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3076\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3077\u001b[0m     )\n\u001b[1;32m-> 3079\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['ppltrst', 'tvtot', 'actrolga', 'euftf', 'gincdif', 'imbgeco', 'stfgov', 'aesfdrk', 'atchctr', 'dscrgnd', 'happy', 'rlgdgr', 'ppltrst.1', 'sclmeet', 'iplylfra'] ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\nexpected actrolga, dscrgnd, atchctr, stfgov, ppltrst.1, euftf, tvtot, iplylfra, rlgdgr, ppltrst, happy, imbgeco, sclmeet, aesfdrk, gincdif in input data\ntraining data did not have the following fields: 2, 12, 7, 6, 18, 19, 16, 11, 14, 8, 3, 1, 10, 13, 0, 5, 15, 9, 17, 4"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('C:/GitHubRepos/ProyectoFinal/data/models/F1GSRF16.pkl', 'rb') as f:\n",
    "    modelo = pickle.load(f)\n",
    "# 1. Información básica del modelo\n",
    "print(modelo)  # Imprime una representación del modelo (similar a la que has proporcionado)\n",
    "\n",
    "# 2. Acceder a los parámetros del modelo\n",
    "print(\"\\nParámetros del modelo:\")\n",
    "print(modelo.get_params())  # Imprime un diccionario con todos los parámetros\n",
    "\n",
    "# 3. Importancia de las características\n",
    "print(\"\\nImportancia de las características:\")\n",
    "print(modelo.feature_importances_)  # Imprime un array con la importancia de cada característica\n",
    "\n",
    "# Si tienes los nombres de las características, puedes crear un DataFrame para visualizarlo mejor\n",
    "# Supongamos que X_train es tu DataFrame de entrenamiento\n",
    "# importancias = pd.DataFrame({'feature': X_train.columns, 'importance': modelo.feature_importances_})\n",
    "# importancias = importancias.sort_values(by='importance', ascending=False)\n",
    "# print(importancias)\n",
    "\n",
    "# 4. Predicciones\n",
    "# Para hacer predicciones, necesitas datos nuevos.  Crea un DataFrame (o array NumPy)\n",
    "# con las mismas características que usaste para entrenar el modelo.\n",
    "# Aquí te doy un ejemplo con datos aleatorios.  Recuerda usar *tus* datos.\n",
    "\n",
    "# Genera datos aleatorios con la misma forma que tus datos de entrenamiento\n",
    "num_filas = 10  # Número de ejemplos para predecir\n",
    "num_caracteristicas = X_train.shape[1] if 'X_train' in locals() else 20 # Obtener el número de características, o usar un valor por defecto si X_train no está definido.\n",
    "nuevos_datos = pd.DataFrame(np.random.rand(num_filas, num_caracteristicas))\n",
    "\n",
    "predicciones = modelo.predict(nuevos_datos)\n",
    "print(\"\\nPredicciones:\")\n",
    "print(predicciones)\n",
    "\n",
    "# 5. Probabilidades de clase (para clasificación)\n",
    "# Para obtener las probabilidades de pertenecer a cada clase, usa predict_proba()\n",
    "probabilidades = modelo.predict_proba(nuevos_datos)\n",
    "print(\"\\nProbabilidades de clase:\")\n",
    "print(probabilidades)\n",
    "\n",
    "# 6. Número de clases\n",
    "print(\"\\nNúmero de clases:\", modelo.n_classes_)\n",
    "\n",
    "# 7.  Obtener el mejor score (si el modelo fue entrenado con GridSearchCV o RandomizedSearchCV)\n",
    "# if hasattr(modelo, 'best_score_'):  # Verifica si el atributo existe (solo si fue entrenado con CV)\n",
    "#     print(\"\\nMejor score:\", modelo.best_score_)\n",
    "\n",
    "# 8.  Obtener los mejores parámetros (si el modelo fue entrenado con GridSearchCV o RandomizedSearchCV)\n",
    "# if hasattr(modelo, 'best_params_'): # Verifica si el atributo existe (solo si fue entrenado con CV)\n",
    "#     print(\"\\nMejores parámetros:\", modelo.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FPJBGPCSobremesa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
